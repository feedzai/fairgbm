FairGBM:

    classpath: fairgbm.FairGBMClassifier

    kwargs:

        #################################
        #   General GBM key-word args   #
        #################################

        n_jobs: 1
    
        boosting_type:
            - goss
            - gbdt

        enable_bundle:
            - False

        # Number of base estimators
        n_estimators:
            type: int
            range: [ 50, 5000 ]
            log: True

        # Max tree leaves for base learners
        num_leaves:
            type: int
            range: [ 4, 32 ]
            log: True

        # min_data_in_leaf
        min_child_samples:
            type: int
            range: [ 5, 500 ]
            log: True

        # Max depth for base learners
        max_depth:
            type: int
            range: [ 2, 10 ]
            log: False

        learning_rate:
            type: float
            range: [ 0.01, 0.5 ]
            log: True

        # Regularization
        reg_alpha:
            type: float
            range: [ 0.0001, 0.1 ]
            log: True

        reg_lambda:
            type: float
            range: [ 0.0001, 0.1 ]
            log: True


        ######################################
        #   FairGBM-specific key-word args   #
        ######################################

        # Fairness constraint parameters
        constraint_type:
            - "FNR,FPR"         # enforce "equalized odds" (equal FPR and TPR)
            # - "FNR"           # enforce "equal opportunity" (equal TPR, or FNR)
            # - "FPR"           # enforce "predictive equality" (equal FPR, or TNR)

        # Search for a good multipliers' learning rate
        multiplier_learning_rate:
            type: float
            range: [0.005, 0.5]
            log: True
            # range: [0.0001, 0.1]       # smaller `multiplier_learning_rate` is better suited for larger datasets
